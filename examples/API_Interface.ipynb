{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution engine interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from my_api_example import execute_pipeline, evaluate_pipeline_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wait for intances to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script1.py', 'read_path': '/tmp/inputs_20200527.csv', 'read_mode': 'once', 'write_mode': 'append', 'operator2_script': '/data/scripts/operator2/aggregation.py', 'threshold': 0.1, 'folds': 2}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script1.py', 'read_path': '/tmp/inputs_20200528.csv', 'read_mode': 'once', 'write_mode': 'concat', 'operator2_script': '/data/scripts/operator2/aggregation.py', 'threshold': 0.5, 'folds': 5}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script1.py', 'read_path': '/tmp/inputs_20200529.csv', 'read_mode': 'once', 'write_mode': 'replace', 'operator2_script': '/data/scripts/operator2/average.py', 'threshold': 0.1, 'folds': 10}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script1.py', 'read_path': '/tmp/inputs_20200530.csv', 'read_mode': 'repeat', 'write_mode': 'append', 'operator2_script': '/data/scripts/operator2/average.py', 'threshold': 0.5, 'folds': 2}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script1.py', 'read_path': '/tmp/inputs_20200531.csv', 'read_mode': 'repeat', 'write_mode': 'concat', 'operator2_script': '/data/scripts/operator2/reduce.py', 'threshold': 0.1, 'folds': 2}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script2.py', 'read_path': '/tmp/inputs_20200527.csv', 'read_mode': 'repeat', 'write_mode': 'replace', 'operator2_script': '/data/scripts/operator2/reduce.py', 'threshold': 0.5, 'folds': 2}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script2.py', 'read_path': '/tmp/inputs_20200528.csv', 'read_mode': 'once', 'write_mode': 'append', 'operator2_script': '/data/scripts/operator2/aggregation.py', 'threshold': 0.1, 'folds': 5}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script2.py', 'read_path': '/tmp/inputs_20200529.csv', 'read_mode': 'repeat', 'write_mode': 'concat', 'operator2_script': '/data/scripts/operator2/average.py', 'threshold': 0.5, 'folds': 10}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script2.py', 'read_path': '/tmp/inputs_20200530.csv', 'read_mode': 'once', 'write_mode': 'concat', 'operator2_script': '/data/scripts/operator2/aggregation.py', 'threshold': 0.1, 'folds': 5}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script2.py', 'read_path': '/tmp/inputs_20200531.csv', 'read_mode': 'once', 'write_mode': 'append', 'operator2_script': '/data/scripts/operator2/aggregation.py', 'threshold': 0.5, 'folds': 5}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script3.py', 'read_path': '/tmp/inputs_20200527.csv', 'read_mode': 'once', 'write_mode': 'append', 'operator2_script': '/data/scripts/operator2/aggregation.py', 'threshold': 0.1, 'folds': 2}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script3.py', 'read_path': '/tmp/inputs_20200528.csv', 'read_mode': 'repeat', 'write_mode': 'concat', 'operator2_script': '/data/scripts/operator2/average.py', 'threshold': 0.5, 'folds': 5}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script3.py', 'read_path': '/tmp/inputs_20200529.csv', 'read_mode': 'once', 'write_mode': 'replace', 'operator2_script': '/data/scripts/operator2/reduce.py', 'threshold': 0.5, 'folds': 10}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script3.py', 'read_path': '/tmp/inputs_20200530.csv', 'read_mode': 'once', 'write_mode': 'replace', 'operator2_script': '/data/scripts/operator2/reduce.py', 'threshold': 0.5, 'folds': 10}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script3.py', 'read_path': '/tmp/inputs_20200531.csv', 'read_mode': 'once', 'write_mode': 'replace', 'operator2_script': '/data/scripts/operator2/average.py', 'threshold': 0.5, 'folds': 10}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script4.py', 'read_path': '/tmp/inputs_20200527.csv', 'read_mode': 'once', 'write_mode': 'append', 'operator2_script': '/data/scripts/operator2/aggregation.py', 'threshold': 0.1, 'folds': 2}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script4.py', 'read_path': '/tmp/inputs_20200528.csv', 'read_mode': 'repeat', 'write_mode': 'concat', 'operator2_script': '/data/scripts/operator2/average.py', 'threshold': 0.5, 'folds': 5}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script4.py', 'read_path': '/tmp/inputs_20200529.csv', 'read_mode': 'repeat', 'write_mode': 'replace', 'operator2_script': '/data/scripts/operator2/reduce.py', 'threshold': 0.5, 'folds': 10}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script4.py', 'read_path': '/tmp/inputs_20200530.csv', 'read_mode': 'repeat', 'write_mode': 'replace', 'operator2_script': '/data/scripts/operator2/aggregation.py', 'threshold': 0.5, 'folds': 5}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script4.py', 'read_path': '/tmp/inputs_20200531.csv', 'read_mode': 'repeat', 'write_mode': 'append', 'operator2_script': '/data/scripts/operator2/reduce.py', 'threshold': 0.1, 'folds': 10}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script5.py', 'read_path': '/tmp/inputs_20200527.csv', 'read_mode': 'once', 'write_mode': 'append', 'operator2_script': '/data/scripts/operator2/aggregation.py', 'threshold': 0.1, 'folds': 2}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script5.py', 'read_path': '/tmp/inputs_20200528.csv', 'read_mode': 'repeat', 'write_mode': 'concat', 'operator2_script': '/data/scripts/operator2/average.py', 'threshold': 0.5, 'folds': 5}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script5.py', 'read_path': '/tmp/inputs_20200529.csv', 'read_mode': 'once', 'write_mode': 'replace', 'operator2_script': '/data/scripts/operator2/reduce.py', 'threshold': 0.1, 'folds': 10}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script5.py', 'read_path': '/tmp/inputs_20200530.csv', 'read_mode': 'once', 'write_mode': 'append', 'operator2_script': '/data/scripts/operator2/aggregation.py', 'threshold': 0.5, 'folds': 10}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script5.py', 'read_path': '/tmp/inputs_20200531.csv', 'read_mode': 'repeat', 'write_mode': 'append', 'operator2_script': '/data/scripts/operator2/reduce.py', 'threshold': 0.5, 'folds': 5}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script6.py', 'read_path': '/tmp/inputs_20200527.csv', 'read_mode': 'once', 'write_mode': 'append', 'operator2_script': '/data/scripts/operator2/aggregation.py', 'threshold': 0.1, 'folds': 2}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script6.py', 'read_path': '/tmp/inputs_20200528.csv', 'read_mode': 'repeat', 'write_mode': 'concat', 'operator2_script': '/data/scripts/operator2/average.py', 'threshold': 0.5, 'folds': 5}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script6.py', 'read_path': '/tmp/inputs_20200529.csv', 'read_mode': 'repeat', 'write_mode': 'replace', 'operator2_script': '/data/scripts/operator2/reduce.py', 'threshold': 0.1, 'folds': 10}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script6.py', 'read_path': '/tmp/inputs_20200530.csv', 'read_mode': 'repeat', 'write_mode': 'concat', 'operator2_script': '/data/scripts/operator2/average.py', 'threshold': 0.1, 'folds': 5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script6.py', 'read_path': '/tmp/inputs_20200531.csv', 'read_mode': 'once', 'write_mode': 'append', 'operator2_script': '/data/scripts/operator2/reduce.py', 'threshold': 0.5, 'folds': 5}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script7.py', 'read_path': '/tmp/inputs_20200527.csv', 'read_mode': 'once', 'write_mode': 'append', 'operator2_script': '/data/scripts/operator2/aggregation.py', 'threshold': 0.1, 'folds': 2}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script7.py', 'read_path': '/tmp/inputs_20200528.csv', 'read_mode': 'repeat', 'write_mode': 'concat', 'operator2_script': '/data/scripts/operator2/average.py', 'threshold': 0.5, 'folds': 5}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script7.py', 'read_path': '/tmp/inputs_20200529.csv', 'read_mode': 'repeat', 'write_mode': 'replace', 'operator2_script': '/data/scripts/operator2/reduce.py', 'threshold': 0.5, 'folds': 10}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script7.py', 'read_path': '/tmp/inputs_20200530.csv', 'read_mode': 'once', 'write_mode': 'concat', 'operator2_script': '/data/scripts/operator2/aggregation.py', 'threshold': 0.5, 'folds': 2}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script7.py', 'read_path': '/tmp/inputs_20200531.csv', 'read_mode': 'repeat', 'write_mode': 'replace', 'operator2_script': '/data/scripts/operator2/aggregation.py', 'threshold': 0.1, 'folds': 5}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script8.py', 'read_path': '/tmp/inputs_20200527.csv', 'read_mode': 'once', 'write_mode': 'append', 'operator2_script': '/data/scripts/operator2/aggregation.py', 'threshold': 0.1, 'folds': 2}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script8.py', 'read_path': '/tmp/inputs_20200528.csv', 'read_mode': 'repeat', 'write_mode': 'concat', 'operator2_script': '/data/scripts/operator2/average.py', 'threshold': 0.5, 'folds': 5}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script8.py', 'read_path': '/tmp/inputs_20200529.csv', 'read_mode': 'once', 'write_mode': 'replace', 'operator2_script': '/data/scripts/operator2/reduce.py', 'threshold': 0.1, 'folds': 10}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script8.py', 'read_path': '/tmp/inputs_20200530.csv', 'read_mode': 'once', 'write_mode': 'append', 'operator2_script': '/data/scripts/operator2/aggregation.py', 'threshold': 0.5, 'folds': 5}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script8.py', 'read_path': '/tmp/inputs_20200531.csv', 'read_mode': 'once', 'write_mode': 'replace', 'operator2_script': '/data/scripts/operator2/average.py', 'threshold': 0.5, 'folds': 10}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script9.py', 'read_path': '/tmp/inputs_20200527.csv', 'read_mode': 'once', 'write_mode': 'append', 'operator2_script': '/data/scripts/operator2/aggregation.py', 'threshold': 0.1, 'folds': 2}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script9.py', 'read_path': '/tmp/inputs_20200528.csv', 'read_mode': 'repeat', 'write_mode': 'concat', 'operator2_script': '/data/scripts/operator2/average.py', 'threshold': 0.5, 'folds': 5}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script9.py', 'read_path': '/tmp/inputs_20200529.csv', 'read_mode': 'once', 'write_mode': 'replace', 'operator2_script': '/data/scripts/operator2/reduce.py', 'threshold': 0.1, 'folds': 10}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script9.py', 'read_path': '/tmp/inputs_20200530.csv', 'read_mode': 'repeat', 'write_mode': 'concat', 'operator2_script': '/data/scripts/operator2/reduce.py', 'threshold': 0.1, 'folds': 10}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script9.py', 'read_path': '/tmp/inputs_20200531.csv', 'read_mode': 'repeat', 'write_mode': 'concat', 'operator2_script': '/data/scripts/operator2/average.py', 'threshold': 0.1, 'folds': 2}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script6.py', 'read_path': '/tmp/inputs_20200527.csv', 'read_mode': 'repeat', 'write_mode': 'concat', 'operator2_script': '/data/scripts/operator2/average.py', 'threshold': 0.1, 'folds': 5}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script9.py', 'read_path': '/tmp/inputs_20200528.csv', 'read_mode': 'once', 'write_mode': 'replace', 'operator2_script': '/data/scripts/operator2/reduce.py', 'threshold': 0.1, 'folds': 2}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script5.py', 'read_path': '/tmp/inputs_20200529.csv', 'read_mode': 'once', 'write_mode': 'append', 'operator2_script': '/data/scripts/operator2/aggregation.py', 'threshold': 0.5, 'folds': 2}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script3.py', 'read_path': '/tmp/inputs_20200527.csv', 'read_mode': 'repeat', 'write_mode': 'replace', 'operator2_script': '/data/scripts/operator2/average.py', 'threshold': 0.5, 'folds': 10}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script6.py', 'read_path': '/tmp/inputs_20200528.csv', 'read_mode': 'once', 'write_mode': 'append', 'operator2_script': '/data/scripts/operator2/reduce.py', 'threshold': 0.5, 'folds': 10}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script4.py', 'read_path': '/tmp/inputs_20200529.csv', 'read_mode': 'once', 'write_mode': 'append', 'operator2_script': '/data/scripts/operator2/aggregation.py', 'threshold': 0.1, 'folds': 5}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script4.py', 'read_path': '/tmp/inputs_20200527.csv', 'read_mode': 'repeat', 'write_mode': 'replace', 'operator2_script': '/data/scripts/operator2/reduce.py', 'threshold': 0.5, 'folds': 2}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script2.py', 'read_path': '/tmp/inputs_20200529.csv', 'read_mode': 'repeat', 'write_mode': 'replace', 'operator2_script': '/data/scripts/operator2/reduce.py', 'threshold': 0.5, 'folds': 2}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script2.py', 'read_path': '/tmp/inputs_20200529.csv', 'read_mode': 'once', 'write_mode': 'replace', 'operator2_script': '/data/scripts/operator2/reduce.py', 'threshold': 0.5, 'folds': 2}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script2.py', 'read_path': '/tmp/inputs_20200529.csv', 'read_mode': 'once', 'write_mode': 'append', 'operator2_script': '/data/scripts/operator2/reduce.py', 'threshold': 0.5, 'folds': 2}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script2.py', 'read_path': '/tmp/inputs_20200529.csv', 'read_mode': 'once', 'write_mode': 'append', 'operator2_script': '/data/scripts/operator2/aggregation.py', 'threshold': 0.5, 'folds': 2}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script2.py', 'read_path': '/tmp/inputs_20200529.csv', 'read_mode': 'once', 'write_mode': 'append', 'operator2_script': '/data/scripts/operator2/aggregation.py', 'threshold': 0.1, 'folds': 2}\n",
      "Executing dataflow_pipeline.json\n",
      "Configuration {'operator1_script': '/data/scripts/operator1/script2.py', 'read_path': '/tmp/inputs_20200529.csv', 'read_mode': 'once', 'write_mode': 'append', 'operator2_script': '/data/scripts/operator2/aggregation.py', 'threshold': 0.1, 'folds': 5}\n"
     ]
    }
   ],
   "source": [
    "import sys, traceback\n",
    "import zmq\n",
    "import ast\n",
    "from bugdoc.utils.utils import record_pipeline_run\n",
    "\n",
    "host = 'localhost'\n",
    "receive = '5557'\n",
    "send = '5558'\n",
    "\n",
    "context = zmq.Context()\n",
    "\n",
    "# Socket to receive messages on\n",
    "receiver = context.socket(zmq.PULL)\n",
    "receiver.connect(\"tcp://{0}:{1}\".format(host,receive))\n",
    "\n",
    "# Socket to send messages to\n",
    "sender = context.socket(zmq.PUSH)\n",
    "sender.connect(\"tcp://{0}:{1}\".format(host,send))\n",
    "\n",
    "\n",
    "# Process tasks forever\n",
    "while True:\n",
    "    data = receiver.recv_string()\n",
    "    fields = data.split(\"|\")\n",
    "    filename = fields[0]\n",
    "    values = ast.literal_eval(fields[1])\n",
    "    parameters = ast.literal_eval(fields[2])\n",
    "    try:\n",
    "        configuration = {\n",
    "            parameters[i] : values[i]\n",
    "            for i in range(len(parameters))\n",
    "        }\n",
    "        output = execute_pipeline(filename,configuration)\n",
    "        result = evaluate_pipeline_output(output)\n",
    "    except:\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "        result = False\n",
    "  \n",
    "    record_pipeline_run(filename,values,parameters,result)\n",
    "    values.append(result)\n",
    "    sender.send_string(str(values))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
